services:
  vllm_llm:
    restart: unless-stopped
    build:
      context: .
      dockerfile: Dockerfile
      platforms:
        - linux/amd64
        - linux/arm64
      tags:
        - "quay.io/ktbs/fd-itbs-dms/vllm_llm:latest"
        - "quay.io/ktbs/fd-itbs-dms/vllm_llm:1.0.0"
    ports:
      - '9001:50001'
    environment:
      - http_proxy
      - HTTP_PROXY
      - https_proxy
      - HTTPS_PROXY
      - no_proxy
      - NO_PROXY
    volumes:
      - hugging_face_cache:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ '1' ]
              capabilities: [ gpu ]

volumes:
  hugging_face_cache: