MODEL_ID="neuralmagic/Meta-Llama-3.1-8B-Instruct-FP8"
TOOL_CALL_PARSER="llama3_json"
ENABLE_TOOL_CALL_PARSER=True
MAX_TOKENS=1024
MAX_MODEL_LEN=8196

TIMEOUT=300

TENSOR_PARALLEL_SIZE=1
ENABLE_PREFIX_CACHING=True
KV_CACHE_TYPE="fp8"
MAX_NUM_SEQS=256

HF_TOKEN=<hugging_face_token>
